{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89dd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the haarcascade_eye.xml cascade classifier\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_detection.xml')\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_face_detection.xml\")\n",
    "cap_image = cv2.imread('cap.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "while True : \n",
    "    # Read the input image\n",
    "    status,photo = cap.read()\n",
    "    # Detect eyes in the image using the cascade classifier\n",
    "    eyes = eye_cascade.detectMultiScale(photo)\n",
    "    myfacerecord = face_cascade.detectMultiScale(photo)\n",
    "    if len(myfacerecord) == 1:\n",
    "       x=myfacerecord[0][0]\n",
    "       y=myfacerecord[0][1]\n",
    "       w = myfacerecord[0][2]\n",
    "       h=myfacerecord[0][3]\n",
    "       center = (x + w // 2, y + h // 2)\n",
    "       radius = min(w, h) // 2\n",
    "       cv2.circle(photo, center, radius, (125, 15, 122), 5)\n",
    "       # Draw rectangles around the detected eyes\n",
    "       cap_width = w\n",
    "       cap_height = h // 2  # You can adjust this value according to the cap image\n",
    "       cap_x_offset = x\n",
    "       cap_height = int(1.5 * h)  # You can adjust this value as needed\n",
    "       cap_y_offset = max(0, y - cap_height // 2)\n",
    "       cap_resized = cv2.resize(cap_image, (cap_width, cap_height))\n",
    "       for c in range(0, 3):\n",
    "           photo[cap_y_offset:cap_y_offset+cap_height, cap_x_offset:cap_x_offset+cap_width, c] = \\\n",
    "           cap_resized[:, :, c] * (cap_resized[:, :, 2] / 255.0) + \\\n",
    "           photo[cap_y_offset:cap_y_offset+cap_height, cap_x_offset:cap_x_offset+cap_width, c] * \\\n",
    "           (1.0 - cap_resized[:, :, 2] / 255.0)\n",
    "       for (x, y, w, h) in eyes:\n",
    "          cv2.rectangle(photo, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "       # Display the image with detected eyes\n",
    "       cv2.imshow('Detected Eyes', photo)\n",
    "       if (cv2.waitKey(10) == 13) :\n",
    "          break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"temp\",cap_image)\n",
    "cv2.waitKey(100)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79805c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Haar cascade XML files for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_face_detection.xml')\n",
    "\n",
    "# Load the images of sunglasses and hat\n",
    "sunglasses_img = cv2.imread('sunglasses.png', -1)\n",
    "\n",
    "# Function to overlay the sunglasses or hat on the face\n",
    "def overlay_image(face_img, overlay_img, x, y, w, h):\n",
    "    \n",
    "    # Resize the overlay image to match the size of the face\n",
    "    overlay_img_resized = cv2.resize(overlay_img, (w, h))\n",
    "\n",
    "    if overlay_img_resized.shape[2] == 4:  # Overlay image has an alpha channel\n",
    "        # Extract the RGB channels from the overlay image\n",
    "        overlay_rgb = overlay_img_resized[:, :, :3]\n",
    "\n",
    "        # Create an alpha mask from the overlay image alpha channel\n",
    "        alpha_mask = overlay_img_resized[:, :, 3] / 255.0\n",
    "\n",
    "        # Create a background mask\n",
    "        background_mask = 1.0 - alpha_mask\n",
    "\n",
    "        # Calculate the overlay region\n",
    "        overlay_region = (face_img[y:y+h, x:x+w] * background_mask).astype(np.uint8)\n",
    "\n",
    "        # Combine the overlay and background regions\n",
    "        face_img[y:y+h, x:x+w] = cv2.add(overlay_region, (overlay_rgb * alpha_mask).astype(np.uint8))\n",
    "    else:  # Overlay image does not have an alpha channel\n",
    "        # Resize the face image to match the dimensions of the overlay image\n",
    "        face_img_resized = cv2.resize(face_img[y:y+h, x:x+w], (overlay_img_resized.shape[1], overlay_img_resized.shape[0]))\n",
    "\n",
    "        # Add the overlay to the face region\n",
    "        face_img_resized = cv2.addWeighted(face_img_resized, 1.0, overlay_img_resized, 0.5, 0)\n",
    "\n",
    "        # Blend the overlayed region back into the original frame\n",
    "        face_img[y:y+h, x:x+w] = face_img_resized\n",
    "\n",
    "    return face_img\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Iterate over the detected faces\n",
    "    if len(faces)==1:\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),[0,255,0],5)\n",
    "            # Add sunglasses to the face\n",
    "            frame = overlay_image(frame, sunglasses_img, x, y + int(h / 4), w, int(h / 2))\n",
    "\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Check for the 'q' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
